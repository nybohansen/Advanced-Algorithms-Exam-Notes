%
%  Created by Kasper Nybo Hansen on 2011-05-22.
%  Copyright (c) 2011 Kasper Nybo Hansen. All rights reserved.
%
%
\documentclass[10pt]{article}

\RequirePackage{nybohansenPreamble}

\newcommand{\authorName}{Kasper Nybo Hansen}
\newcommand{\authorEmail}{nybo@diku.dk}
\newcommand{\titleName}{Exam Notes}
\newcommand{\courseName}{Advanced Algorithms}

\author{\authorName \\\texttt{\small{\authorEmail}}}
\title{\textsc{\titleName \\ \courseName}}
% \date{}
\makeindex

\begin{document}

\maketitle 

\tableofcontents

\section{Max Flow} % (fold)
\label{sec:max_flow}

The problem of max flow is finding a flow in a directed graph from a source to a sink. In the case of multiple sources and sinks, one can extend the graph by introducing a \emph{super source} and a \emph{super sink}.

\subsection{Definitions} % (fold)
\label{sub:definitions}
Let $G = (V,E)$ be a directed graph containing a source vertex $s \in V$ and sink vertex $t \in V$. Let every node $v \in V$ be reachable from $s$ and let $t$ be reachable from every node $v \in V$. Let each edge $(u,v) \quad \forall u,v \in V$ have a capacity $c(u,v) \geq 0$. The a flow is a real-valued function $f: V \times V \leftarrow R$, satisfying the capacity constraint and the flow conservation property. The capacity constraint says that the flow of an edge cannot exceed the capacity i.e
\begin{equation}
  0 \leq f(u,v) \leq c(u,v)
\end{equation} 
and the flow conservation property says that the total flow going into a vertex $u$ must be equal to the total flow going out of the vertex $u$, where $u \in V \setminus \{s,t\}$ i.e
\begin{equation}
  \sum_{v \in V} f(v,u) = \sum_{v \in V} f(u,v) \qquad u \in V \setminus \{s,t\}
\end{equation} 
The flow value, $|f|$, is calculated as
\begin{equation}
  |f| = \sum_{v \in V} f(s,v) - \sum_{v \in V} f(v,s)
\end{equation}
i.e. the flow value is calculated as the total flow going out of the source vertex minus the total flow going in.
% subsection definitions (end)

\subsection{Residual network} % (fold)
\label{sub:residual_network}
Let $f$ be a feasible flow in $G = (V,E)$. Let $G_f$ denote the residual network of $G$ induced by $f$, and let $f'$ be a flow in $G_f$. Then the function 
\begin{equation}
  (f \uparrow f')(u,v) = f(u,v)+f'(u,v)-f'(v,u) \qquad \forall (u,v) \in E
\end{equation}
denotes the augmentation of flow $f$ by flow $f'$.

It can be shown that $f \uparrow f'$ is a flow in $G$ and that the value is $|f \uparrow f'| = |f| + |f'|$.
% subsection residual_network (end)

\subsection{Cut} % (fold)
\label{sub:cut}
Given a graph $G = (V,E)$ a cut is a partitioning such that $V$ is divided into two subset $X$ and $Y$. We define the flow across a cut as
\begin{equation}
  f(X,Y) = \sum_{x \in X} \sum_{y \in Y} f(x,y) - \sum_{x \in X} \sum_{y \in Y} f(y,x)
\end{equation} 
thus the flow value of a cut is the total flow going from one subset to the other minus the total flow going the other way.

Let $G = (V,E)$, $X  = \subset V$, $Y = V \setminus X$, $s \in X$ and $t \in Y$. The partition $(X,Y)$ is then called a cut. The \emph{net flow} is defined as $f(X,Y)$. The capacity of the cut is defined as

\begin{equation}
 c(X,Y) = \sum_{u \in X, v \in Y} c(u,v)
\end{equation}
thus the capacity of a cut, is the total capacity of all connections between the two subsets.

% subsection cut (end)

\subsection{Min-cut theorem} % (fold)
\label{sub:min_cut_theorem}
A Min-cut is a cut where the capacity over all cuts is minimized. We thus choose to partition the $V$ such that the capacity, $c(X,Y)$, between the two sets are minimized.

Show that an augmenting path increases the flow value. This is intuitively true, since when finding an augmenting path, it is added to the original graph.

Show that the flow value has an upper bound. Let $V$, in a graph $G = (V,E)$, be partitioned into two subsets, $S$ and $T$. The flow value then has a upper bound equal to the capacity of the cut. The following proves this statement
\begin{align*}
 |f| &= f(S,T)  \\ 
     &= \sum_{s \in S} \sum_{t \in T} f(s,t) - \sum_{s \in S} \sum_{t \in T} f(t,s) \\
     &\leq \sum_{s \in S} \sum_{t \in T} f(s,t) \\
     &\leq \sum_{s \in S} \sum_{t \in T} c(s,t) \\
     &= c(S,T)
\end{align*}


\begin{theorem}

  Given a graph $G = (V,E)$ and a flow $f$ ($f$ does not necessarily be a max flow), the min-cut theorem states that the following three statements are equivalent

  \begin{enumerate}
    \item $f$ is a maximum flow in G, i.e the flow value, $|f|$, is maximized
    \item There are no augmenting paths in the residual network, $G_f$
    \item $|f| = c(S,T)$ for some cut $(S,T)$ in $G$
  \end{enumerate}
  
\end{theorem}

\begin{proof}

The proof is done in a circular fashion. We will start by showing $1 \Rightarrow 2$ by contradiction.   
  
Let $f$ be a maximum flow in $G$. Let there be an augmenting path in the residual network. Hence there is a nonzero flow $f'$ in $G_f$. Thus $f \uparrow f'$ is stictly greater than $f$. This is a contradiction compared to our initial belief that $f$ was a maximum.
\end{proof} 

We will now show $2 \Rightarrow 3$
\begin{proof}
Assume that there are no augmenting paths in $G_f$, i.e. there are no paths between $s$ and $t$ in $G_f$, and they are there disconected. Now partition $G$ into two subsets, $S$ and $T$, such that $S = \{v \in V: \text{There is a path from $s$ to $v$ in $G_f$}\}$ and $T = V\setminus S$. I.e. $S$ contains the vertices reachable from the source node $s$ in $G_f$. Then $(S,T)$ is a cut. We now want to show that the value of this cut is equal to $|f|$. 

Let $u \in S$ and $v \in T$. 

If the edge $(u,v) \in E$, i.e. $(u,v)$ is an edge going from $S$ to $T$, then the flow going through this edge must be equal to the capacity, i.e. $f(u,v) = c(u,v)$ otherwise $(u,v) \in E_f$ which would place $v$ in set $S$. 

If the edge $(v,u) \in E$, i.e. $(v,u)$ is an edge going from the $T$ to $S$, then we must have that $f(v,u)=0$, otherwise $c_f(u,v) = f(v,u)$ would be positive and therefore $(u,v) \in E_f$ which would place $v$ in set $S$.

Thus the flow of the cut is

\begin{align*}
 f(S,T) &= \sum_{u \in S} \sum_{v \in T} f(u,v) - \sum_{u \in S} \sum_{v \in T} f(v,u) \\
        &= \sum_{u \in S} \sum_{v \in T} f(u,v) - 0 \\ 
        &= c(S,T) 
\end{align*}
\end{proof} 


The final thing we need to show is $3 \Rightarrow 1$. We thus need to show that $|f| = c(S,T)$ implies that $|f|$ is maximized. 

\begin{proof}
  We have shown that a flow has a upper bound of $c(S,T)$ i.e. $|f| \leq c(S,T)$. This means that $|f|$ must be maximized when $|f| = c(S,T)$.  
\end{proof}

The min-cut is the dual of the max flow.

% subsection min_cut_theorem (end)
                                                          
\subsection{Ford-Fulkerson and Edmonds Karp} % (fold)
\label{sub:ford_fulkerson_and_edmonds_karp}
The Ford-Fulkersen method works as follows:
\begin{verbatim}
  Initialize all edges to have a 0 flow
  Construct the residual network G_f   
  while augmenting paths exists in G_f do
    Find an augmenting path in G_f
    augment f with the max value found in the augmenting path 
    Construct the residual network for the increased flow
  loop 
\end{verbatim}

An example of running the Ford-Fulkerson method can be seen on figure \ref{fig1}

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig1.pdf}
\caption{Example of running the Ford-Fulkerson method. Left side is the flow network, right side is the residual network, with bold lines representing augmenting paths.}
\label{fig1}
\end{figure}

The running time of the Ford-Fulkerson can be expressed as $\O(E\dot f*)$ where $f*$ denotes the value of the max flow. At each iteration we search through $\O(E)$ edges, and the maximum number of iterations is $f*$. An illustration of this running time can be seen in figure \ref{fig2}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig2.pdf}
\caption{Illustration of the complexity of the Ford-Fulkerson algorithm}
\label{fig2}
\end{figure}

This running time can be improved by selecting the augmenting path by breath first. Breath first chooses the shortest path with capacity between the source and sink. This is exactly what Edmonds-Karp does, thus Edmonds-Karp is a specialized version of the Ford-Fulkerson method. The running time of Edmonds-Karp is $\O(V^2E)$.


% subsection ford_fulkerson_and_edmonds_karp (end)

% section max_flow (end)
\clearpage \newpage
\section{Linear Programming} % (fold)
\label{sec:linear_programming}

In linear programming we want to maximize (or minimize) a linear function, under a number of constraints. An example of a linear program is
\begin{align}
 \max &\quad x_1 + x_2 \label{linprop1}\\ 
 \text{St.} &\quad  4x_1 - x_2  \leq 8 \nonumber\\
            &\quad  2x_1 + x_2  \leq 10 \nonumber\\
            &\quad  5x_1 - 2x_2 \leq -2 \nonumber\\            
            &\quad  x_1,x_2,x_3 \geq 0  \nonumber
\end{align}
\ref{linprop1} is called the objective function.
                                                                      
A linear program in 2 dimensions can be illustrated as figure \ref{fig3}. The gray area is called the feasible region.
\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{figures/fig3.pdf}
\caption{Illustration of a simple linear program where the objective function is $x_1 + x_2$. The feasible region is gray.}
\label{fig3}
\end{figure}

A linear program can be written in two ways. Standard form and slack form. When a linear program is written in standard form it takes the following form
\begin{align*}
\max &\quad \sum_{j=1}^n c_jx_j  \\ 
 \text{S.t.} &\quad \sum_{j=1}^n a_{ij}x_j \leq b_i \qquad i=1,2,\ldots,m\\
             &\quad x_j \geq 0 \qquad i=1,2,\ldots,n\\
\end{align*}
where $m$ is the number of constraints and $n$ is the number of variables. One could think of $a$ as a matrix having, $m$ rows and $a$ columns. Every linear program can be rewritten to slack form. 

\subsection{Converting into standard form} % (fold)
\label{sub:converting_into_standard_form}
A linear program does not have to take standard form. But we can always turn a linear program into standard form. The following section describes how to convert a non-standard form linear program into standard form.

\begin{itemize}
  \item If the program is a minimization problem, then it can be turned into a maximization problem by multiplying the objective function by -1. The constraints are not changed, since the feasible region is the same, regardless if we want to maximize or minimize an objective function under the same constraints.                                                                         
  \item If the linear program contains variables, $x_j$ without nonnegative constraints we can replace $x_j$ so $x_j = x_j'-x_j''$, and add the constraints $x_j', x_j''>0$.
  \item If the linear program contains equality constraints, then replace each equality with to inequality constraints going opposite ways, i.e $a = b \Leftrightarrow a \leq b \wedge a \geq b$. 
  \item If the linear program contains inequality constraints, but instead of less than, they are greater than, then multiply the constraint with $-1$.
\end{itemize}

The following is an example of how to convert a non-linear program into standard form. 
\begin{align*}
 \min &\quad -2x_1 + 3x_2  \\ 
 \text{St.} &\quad  x_1 + x_2  = 7 \\
            &\quad  x_1 - 2x_2 \leq 4 \\
            &\quad  x_1        \geq 0  
\end{align*}

Start by making it a maximization problem, i.e. multiply the objective function with $-1$.
\begin{align*}
 \max &\quad 2x_1 - 3x_2  \\ 
 \text{St.} &\quad  x_1 + x_2  = 7 \\
            &\quad  x_1 - 2x_2 \leq 4 \\
            &\quad  x_1        \geq 0  
\end{align*}
Next place $x_2$ under the nonnegative constraint. Let $x_2 = x_2'-x_2''$ then
\begin{align*}
 \max &\quad 2x_1 - 3x_2' +3x_2''  \\ 
 \text{St.} &\quad  x_1 + x_2'-x_2''  = 7 \\
            &\quad  x_1 - 2x_2' +2x_2'' \leq 4 \\
            &\quad  x_1, x_2', x_2''    \geq 0  
\end{align*}
Make a cleanup so we remove those pesky primes, just rename $x_2' = x_2$ and $x_2'' = x_3$.
\begin{align*}
 \max &\quad 2x_1 - 3x_2 +3x_3  \\ 
 \text{St.} &\quad  x_1 + x_2-x_3  = 7 \\
            &\quad  x_1 - 2x_2 +2x_3 \leq 4 \\
            &\quad  x_1, x_2, x_3    \geq 0  
\end{align*}
Lets remove the equality sign, by replacing the equality with to opposite directed inequalities i.e.
\begin{align*}
 \max &\quad 2x_1 - 3x_2 +3x_3  \\ 
 \text{St.} &\quad  x_1 + x_2-x_3  \leq 7 \\
            &\quad  x_1 + x_2-x_3  \geq 7 \\
            &\quad  x_1 - 2x_2 +2x_3 \leq 4 \\
            &\quad  x_1, x_2, x_3    \geq 0  
\end{align*}
Final thing we need to do, is to turn the greater than into a less than my multiplying with $-1$, i.e.
\begin{align}
 \max &\quad 2x_1 - 3x_2 +3x_3  \label{linprop2}\\ 
 \text{St.} &\quad  x_1 + x_2-x_3  \leq 7 \nonumber\\
            &\quad  -x_1 - x_2 + x_3  \leq -7 \nonumber\\
            &\quad  x_1 - 2x_2 +2x_3 \leq 4 \nonumber\\
            &\quad  x_1, x_2, x_3    \geq 0  
\end{align}
and the linear program in now in standard form.
% subsection converting_into_standard_form (end)


\subsection{Slack form} % (fold)
\label{sub:slack_form}
In slack form, the inequalities are replaced by equalities and a number of slack variables are introduced. We can rewrite the standard form linear program shown in \ref{linprop2} to slack form as
\begin{align*}
 \max &\quad 2x_1 - 3x_2 +3x_3 \\ 
 \text{St.} &\quad  x_4 = 7 - x_1 - x_2 + x_3\\
            &\quad  x_5 = -7 + x_1 + x_2 -x_3\\
            &\quad  x_6 = 4 -x_1 + 2x_2 -2x_3\\
            &\quad  x_1, x_2, x_3, x_4, x_5, x_6    \geq 0  
\end{align*}
We have just introduced the three \emph{basic variables} $x_4,x_5,x_6$ and rearranged the original non-basic variables. In general when going from standard to slack form, you need $m$ new slack variables, where $m$ denotes the number of constraints.
% subsection slack_form (end)

\subsection{SIMPLEX algorithm} % (fold)
\label{sub:simplex_algorithm}
There exists several methods to solve linear programs. Some methods are polynomial, but doesn't work well in practice. A non polynomial method is called simplex. Simplex has it name from the shape of the feasible region.

The geometric interpretation of SIMPLEX is as follows. It starts at a corner point: the origin, and looks at the edges incident with that point. Then it chooses one, and moves along an edge which makes the objective value get larger (or stay the same). If the edge goes on forever, then the LP is unbounded; if the edge does not go on forever, it ends up at another corner point. Then the Simplex Method does the same thing over and over again, until it stops at a certain point. That point is the place where the objective value is the largest.


Normally, this would only lead you to a local maximum, instead of the global maximum, but this cannot happen when solving a LP. This is because the objective values and inequalities are linear in form.

Given a linear program

\begin{align}
  \max &\quad 2x_1 - x_2 \label{aux1}\\ 
  \text{St.} &\quad  2x_1 - x_2  \leq 7 \nonumber\\
             &\quad  x_1 - 5x_2  \leq -7 \nonumber\\
             &\quad  x_1, x_2    \geq 0 
\end{align}

Simplex needs the problem in standard form, it starts by converting the problem into slack form, i.e.
\begin{align}
  z  &= 2x_1 - x_2 \label{aux2}\\ 
  x_3 &= 7 - 2x_1 + x_2 \nonumber\\
  x_4 &= -7-x_1 + 5x_2  \nonumber\\
  &x_1, x_2, x_3, x_4    \geq 0 
\end{align}


it then finds a initial solution. Typically this solution is found by setting the variables to $0$. Sometimes the initial solution isn't feasible as can be see in \ref{aux2}. In this case, we need to formulate an auxiliary program. The auxiliary program for \ref{aux1} is

\begin{align}
  \max &\quad -x_0 \\ 
  \text{St.} &\quad  2x_1 - x_2 -x_0 \leq 2 \nonumber\\
             &\quad  x_1 - 5x_2 -x_0 \leq -4 \nonumber\\
             &\quad  x_1, x_2,x_0    \geq 0 \nonumber 
\end{align}
 
The auxiliary program is then solved with the SIMPLEX algorithm. It starts by rewriting the problem into slack form
\begin{align}
    z &= -x_0 \\ 
  x_3 &= 2 - 2x_1 + x_2 + x_0  \nonumber\\
  x_4 &= -4 - x_1  + 5x_2 + x_0  \nonumber\\
  &x_0, x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}
And pivot's, so $x_0$ enters the basis, on the constraint that is most negative
\begin{align}
    z &= -x_0 \\ 
  x_3 &= 2 - 2x_1 + x_2 + x_0  \nonumber\\
  x_0 &= 4 + x_1 -5x_2 + x_4    \nonumber\\
  &x_0, x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}
and substitutes $x_0$ into the objective function and the constraints
\begin{align}
    z &= -4 - x_1 + 5x_2 - x_4\\ 
  x_0 &= 4 + x_1 - 5x_2 + x_4   \nonumber\\
  x_3 &= 6 - x_1 - 4x_2 + x_4   \nonumber\\
  &x_0, x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}
The basic feasible solution to this problem is $(x_0, x_1, x_2, x_3, x_4) = (4, 0, 0, 6, 9)$. We want the optimal solution so we need to do a pivot. Since $5x_2$ is the only one that is nonnegative, we investigate this: $x_0$ binds with $4/5=16/20$, and $x_3$ binds with $6/4=30/20$. We thus choose to pivot on $x_0$ and $x_2$, since $x_0$ is the most binding.
\begin{align}
    z &= -4 - x_1 + 5(\frac{4}{5} - \frac{1}{5} x_0 + \frac{1}{5} x_1 + \frac{1}{5} x_4) - x_4\\ 
  x_2 &= \frac{4}{5} - \frac{1}{5} x_0 + \frac{1}{5} x_1 + \frac{1}{5} x_4    \nonumber\\
  x_3 &= 6 - x_1 - 4(\frac{4}{5} - \frac{1}{5} x_0 + \frac{1}{5} x_1 + \frac{1}{5} x_4) + x_4   \nonumber\\
  &x_0, x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}
reducing yields
\begin{align}
    z &= - x_0 \label{aux3}\\ 
  x_2 &= \frac{4}{5} - \frac{1}{5} x_0 + \frac{1}{5} x_1 + \frac{1}{5} x_4    \nonumber\\
  x_3 &= \frac{14}{5} + \frac{4}{5} x_0 - \frac{9}{5} x_1 + \frac{1}{5} x_4    \nonumber\\
  &x_0, x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}
this slack form is the final solution to the auxiliary problem. Since $x_0 = 0$ we know it's optimal, and that the initial problem was feasible. Since $x_0=0$ we can remove it from the set of constraints. The original objective function \ref{aux2} can then be restored, substituting the basic variables from \ref{aux1}, and retaining the constraints form \ref{aux3}

\begin{align}
    z &= - \frac{4}{5} + \frac{9}{5} x_1 - \frac{1}{5} x_4\\ 
  x_2 &= \frac{4}{5} + \frac{1}{5} x_1 + \frac{1}{5} x_4    \nonumber\\
  x_3 &= \frac{14}{5} - \frac{9}{5} x_1 + \frac{1}{5} x_4    \nonumber\\
  &x_1, x_2, x_3, x_4    \geq 0 \nonumber 
\end{align}

Setting this slack form to zero, yields the basic solution $(x_1, x_2, x_3, x_4) = (0, \frac{4}{5} , \frac{14}{5} , 0)$. This slack form can now be solved by using the SIMPLEX algorithm again.

a flow chart of the simplex can be seen in figure \ref{fig4}

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig4.pdf}
\caption{Flowchart of the SIMPLEX algorithm}
\label{fig4}
\end{figure}


% subsection simplex_algorithm (end)

\subsection{Duality} % (fold)
\label{sub:duality}

Duality means that finding a solution in one problem 

Given a linear program with $n$ variables and $m$ constraints
\begin{align}
 \max &\quad \sum_{j=1}^n c_jx_j  \nonumber\\ 
 \text{S.t.} &\quad \sum_{j=1}^n a_{ij}x_j \leq b_i \qquad i=1,2,\ldots,m\label{dual10}\\
             &\quad x_j \geq 0 \qquad i=1,2,\ldots,n \nonumber
\end{align}
and call this the \emph{primal}. We define the \emph{dual} as 
\begin{align}
 \min &\quad \sum_{i=1}^m b_iy_i  \nonumber\\ 
 \text{S.t.} &\quad \sum_{j=1}^m a_{ij}y_i \geq c_j \qquad j=1,2,\ldots,n \label{dual0}\\
             &\quad y_j \geq 0 \qquad i=1,2,\ldots,m \nonumber
\end{align}
The dual is a minimization problem and it has $m$ variables and $n$ constraints. Furthermore the less-than-equal-to has been replaced by greater-than-equal-to. Each $b_i$ in the primal is now part of the objective function as a coefficient. Each $c_j$ in the primal is now the right handside of the constraints. If $a$ was a matrix then in the dual it is transposed. 

Example: Let the primal be
\begin{align}
 \max &\quad 3x_1 + x_2 + 2x_3\label{dual1}\\ 
 \text{St.} &\quad  x_1  + x_2  + 3x_3 \leq 30 \nonumber\\
            &\quad  2x_1 + 2x_2 + 5x_3 \leq 24 \nonumber\\
            &\quad  4x_1 + x_2  + 2x_3 \leq 36 \nonumber\\            
            &\quad  x_1,x_2,x_3 \geq 0  \nonumber
\end{align}
then the dual is
\begin{align}
 \min &\quad 30y_1 + 24y_2 + 36y_3 \label{dual2}\\ 
 \text{St.} &\quad  y_1 + 2y_2  + 4y_3 \leq 3 \nonumber\\
            &\quad  y_1 + 2y_2  + 1y_3 \leq 1 \nonumber\\
            &\quad  3y_1 + 5y_2  + 2y_3 \leq 2 \nonumber\\            
            &\quad  x_1,x_2,x_3 \geq 0  \nonumber
\end{align}

Weak linear-programming duality states the following
\begin{theorem}
  Given a feasible solution to the primal problem, $\bar{x}$, and a feasible solution to the dual problem, $\bar{y}$, then
  \begin{equation}
  \sum_{j=1}^n c_jx_j \leq \sum_{i=1}^m b_iy_i
  \end{equation}  
\end{theorem}
said in words: the primal is bounded above by the dual.

\begin{proof}
Let $\bar{x}$ and $\bar{y}$, be feasible solutions to the primal and the dual respectively.

From \ref{dual0} we know that $\sum_{j=1}^m a_{ij}y_i \geq c_j$. Thus we can write
\begin{equation}
\sum_{j=1}^n c_j\bar{x}_j \leq  \sum_{j=1}^n \left (\sum_{j=1}^m a_{ij}\bar{y}_i\right)\bar{x}_j   
\end{equation}
exchanging $\bar{x}_i$ and $\bar{y}_i$ yields
\begin{equation}
\sum_{j=1}^n c_j\bar{x}_j \leq  \sum_{j=1}^n \left (\sum_{j=1}^m a_{ij}\bar{x}_j\right)\bar{y}_i
\end{equation}
and \ref{dual10} gives us $\sum_{j=1}^m a_{ij}x_j \leq b_i$ which we can insert
\begin{equation}
\sum_{j=1}^n c_j\bar{x}_j \leq  \sum_{j=1}^m b_i\bar{y}_i
\end{equation}
and we arrive what we wanted to prove.
\end{proof}

The duality theorem states that if a feasible solution of the primal, is equal to a feasible solution to the dual, the this feasible solution is optimal to both the primal and the dual. More precisely the theorem states

\begin{theorem}
Let SIMPLEX terminate with a feasible basic solution $\bar{x}*=(x_1*,x_2*,\ldots,x_n*)$, and let $N$ denote the nonbasic and $B$ the basic variables for the final slack form. Let $c'$ denote the coefficients of the objective function in the final slack form. 

Not let $\bar{y}* = (y_1*,y_2,\ldots,y_m)$ be defined as

\begin{equation} 
\bar{y}* = 
\left\{
\begin{array}{rl} 
  -c'_{n+i} & \text{if } (n+i) \in N \\
   0 & \text{otherwise}
\end{array} 
\right. 
\end{equation} 

then $\bar{x}*$ is an optimal solution to the primal, and $\bar{y}*$ is an optimal solution to the dual and
\begin{equation}
  \sum_{j=1}^n c_jx_j* = \sum_{i=1}^m b_iy_i*
\end{equation}
\end{theorem}

\begin{proof}
In order to prove the above, we have to show that $\bar{y*}$ is a feasible solution to the dual, and that 
\begin{equation}
  \sum_{j=1}^n c_jx_j* = \sum_{i=1}^m b_iy_i*  
\end{equation}
\end{proof}
 
% subsection duality (end)

% section linear_programming (end)

\clearpage \newpage

\section{NP-completeness} % (fold)
\label{sec:np_completeness}

NP-complete problems is a class of problems that has algorithms that run in \emph{super polynomial} time, i.e. there running time is thus $>\O(N^k)$, for some constant $k$.

NP-completeness only applies to decision problems. A optimization problem can easily be made into a decision problem by setting a bound. E.g. a shortest path problem\footnote{Finding the shortest path between two nodes in a graph} can be made into a decision problem, by asking: Is there a shortest path between these two nodes with at most length $k$?.  

When we are proving something is NP-complete, and therefore hard to solve, we are proving it under the constraint that no polynomial algorithm exist for a NP-complete problem. This assumption is still not proved formally (But if this does not hold, we have a BIG problem!).


\subsection{Language} % (fold)
\label{sub:language}
A language describes a problem. E.g. the language for the Hamilton cycle problem can be described as "Does the graph $G$ have a Hamilton cycle", or more formally
\begin{equation}
HAM-CYCLE = \{\langle G \rangle\: G \text{ is a hamilton cycle}\}   
\end{equation}
The contents between the $\langle$ and $\rangle$ is the input to the problem.
% subsection language (end)

\subsection{Reduction algorithm} % (fold)
\label{sub:reduction_algorithm}
Suppose we have a decision problem $A$ that we want to solve in polynomial time. Now suppose we already know how to solve a different decision problem, $B$, in polynomial time. Finally suppose we have a algorithm that transforms an instance $a \in A$, into an instance $b \in B$ with the following characteristics
\begin{itemize}
  \item The transformation is done in polynomial time
  \item The answers are the same, i.e $a \Leftrightarrow b$.
\end{itemize}
this algorithm is then called a \emph{reduction algorithm}. 

The key point in the reduction algorithm, is that it runs in polynomial time. Suppose we had an instance of a non-polynomial problem we could transform, in polynomial time, into an other problem that could be solved by a polynomial algorithm. The final result would be a running time of $\O(n^{k_1})+O(n^{k_2}) = O(n^k)$ yielding a polynomial algorithm to a non-polynomial problem.

Formally we say that a problem $L_1$ is polynomial time reducible to $L_2$, i.e. $L_1 \leq_p L2$ if there exist a function $f$ such
\begin{equation}
  x \in L_1 \Leftrightarrow f(x) \in L_2 \label{eq15}
\end{equation}
we call $f$ a \emph{reduction function} and it can be computed by a reduction algorithm.

% subsection reduction_algorithm (end)


\subsection{Definition of classes} % (fold)
\label{sub:definition_of_classes}

We call the class of problems for which a polynomial time algorithm is known for $P$. More formally  
\begin{definition}
Let $p \in P$ be a problem in $P$. Then there exist a polynomial algorithm that can solve the $p$ in time $\O(n^k)$, where $n$ is the input size and $k$ is a constant. The language for $P$ is
\begin{equation}
  P = \{\text{L: L is accepted be a polynomial-time algorithm}\}
\end{equation}
\end{definition}
Examples of problems contained within $P$ is most sorting algorithms, some graph algorithms etc.

We call the class of problems for which a solution can be verified in polynomial time for $NP$. More formally the complexity class $NP$ has the language
\begin{equation}
  NP = \{\text{L: There exists an A, such that L is verified in polynomial time}\}
\end{equation}
i.e. the NP class consist of all the problem instances $L$ for which we can verify a solution using $A$ in polynomial time.

A language $L$ is np-complete if 
\begin{enumerate}
  \item $L \in NP$
  \item $L' \leq_p L \qquad \forall L' \in NP$ \label{prop2}
\end{enumerate}
In the case where only property \ref{prop2} is satisfied the problem is called \emph{np-hard}.

Figure \ref{fig5} illustrates the 3 classes in a set manner.
\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{figures/fig5.pdf}
\caption{Set illustration of the 3 classes of problems. Note that both $P$ and $NPC$ is in $NP$, but they are disjoint i.e. this illustration assumes that $P \neq NP$}
\label{fig5}
\end{figure}


\begin{theorem}
Let $L_1$ and $L_2$ be languages such that $L_1 \leq_p L_2$. Then if $L_2 \in P$ then $L_1 \in P$  
\label{theorem1}
\end{theorem}

\begin{proof}
We know that $L_2$ can be solved in polynomial time. From \ref{eq15} we know that there exist a function $f$ such that $x \in L_1 \Leftrightarrow f(x) \in L_2$. For any $x \in L_1$ we can thus use the result $f(x) in L_2$ and find the answer to the instance $x$. $L_1$ can thus be solved in polynomial time.  
\end{proof}

\begin{theorem}
If any NP-complete problem is solvable in polynomial time, all NP-complete problems are solvable in polynomial time.
\end{theorem}

\begin{proof}
  Suppose that $L \in P$ and also that $L \in NPC$. For any $L' \in NP$ we have $L' \leq_p L$, by property \ref{prop2} of NP-completeness. Since $L \in P$ there must exist a polynomial algorithm. And by \ref{theorem1} this implies that $L' \in P$.
\end{proof}


% subsection definition_of_classes (end)

\subsection{Example $HAM-CYCLE \leq_p TSP$} % (fold)
\label{sub:subsection_name}
In this example we wish to prove that it is very unlikely that a polynomial algorithm exist for the Traveling Salesman Problem (TSP). In fact, we wish to show that solving the TSP is at least as hard as solving the Hamiltonian cycle. We know that the Hamiltonian cycle problem is NP-complete. 

Recall that a Hamilton cycle is a path in a undirected graph where each vertex is visited exactly once.

Thus, if we can show that it is at least as has to solve TSP as to solve the Hamiltopnian cycle, we have shown that TSP is in the NP-completeness class. 

Let the language of the TSP be defined as

\begin{align*}
TSP = \{\langle G, c, k \rangle : & G = (V,E) \text{ is a complete graph}, \\ 
                                  & c:V \times V \rightarrow \Z, \\
                                  & k \in \Z, \\
                                  & \text{$G$ has a TSP tour of at most cost $k$}\}
\end{align*}


We need to show two things. First we need to show that the TSP decision problem is in the NP class. This can be shown by showing that TSP has a verification algorithm, that can verify an instance in polynomial time. 

Let the verification algorithm check the sequence of vertices and sums the total cost and verifies this as being $\leq k$. Such a verification algorithm definitely exist, and can be run in polynomial time.

The next thing we need to show is $HAM-CYCLE \leq_p TSP$. 

Let $G=(V,E)$ be an instance of $HAM-CYCLE$. We can construct an instance of TSP as follows. Form the complete graph\footnote{A complete graph has a path from every vertex to all other vertices.} $G' = (V,E')$. Let the vertices in $V$ be the cities in the TSP. Let the cost function, $c(i,j)$ be defined by

\begin{equation} 
c(i,j) = 
\left\{
\begin{array}{rl} 
  0 & \text{if } (i,j) \in E \\
  1 & \text{if } (i,j) \notin E 
\end{array} 
\right. 
\end{equation} 
So if a edge resides in the Hamilton graph $G$, then it has cost $0$ in $G'$ otherwise $1$. An instance of TSP is thus a cycle in $G'$ with cost at most $0$.

It is clear that we can construct $G'$ in polynomial time. We now show that $G$ contains a Hamilton cycle if and only if graph $G'$ has a tour of cost $0$. Suppose $G$ has a Hamilton cycle $h$. Each edge in $h$ resides in $G$ thus having cost $0$ in $G'$. Conversely, suppose $G'$ has a tour $h'$ of cost $0$, since the cost of the edges in $G'$ is $0$ and $1$, $h'$ can only occur if it traverses the edges of $G'$ with $0$ cost, thus $h'$ contains only edges from $E$.  


We have now proven that finding 
% subsection subsection_name (end)

% section np_completeness (end)

\section{Branch and Bound and Metaheuristics} % (fold)
\label{sec:branch_and_bound_and_metaheuristics}


\subsection{Examples of NP hard problems} % (fold)
\label{sub:exmaples_of_np_hard_problems}

% subsection exmaples_of_np_hard_problems (end)


\subsection{Branch and reduce} % (fold)
\label{sub:branch_and_reduce}
Maximum independent set as example
% subsection branch_and_reduce (end)



\subsection{Branch and bound} % (fold)
\label{sub:branch_and_bound}
TSP as an example
% subsection branch_and_bound (end)
NP-hard problems can be solved to closed form by using an exact algorithm like branch and bound. They can be solved heuristically by using meta algorithms.

The search space for NP-hard problems are extremely large, and solving problems exact means, to some extent that we need to traverse the whole search space. Solving heuristically means to traverse part of the search space, thereby gaining a speedup.



Branch and Bound and Metaheuristics are  distributed notes ([Clausen] sections 1 and 2], [Luke] sections 0,1 and 2, [Fomin and Kratsch] chapter 1 and chapter 2).                                                                                                                                                          
% section branch_and_bound_and_metaheuristics (end)

\section{Approximation Algorithms} % (fold)
\label{sec:approximation_algorithms}

Approx Exam
Vertex cover appeox 2

Tsp approx 2 with triangle eq. Interesting if triangle not holds
Non approx algo if triangle not holds

Set cover

Good example Also to show how linear programme Can solcve set cover

Vertex cover, TSP, Set cover algorithm

Approximation Algorithms - CLRS, Chapter 35

Notes taken in class:
Approximate vertex cover an alternative way. Linear programming can be used in approx. algorithms. We want to solve vertex cover in a "weighted" version, called weighted vertex cover. Instead of wanting to archive the minimum number of nodes, we want to archive the minimum weight of the nodes.

Let every node $v_n$ have a weight $w(v_n)$. Goal: To minimize the total weight $\sum_{\forall v \in V} w(v)$ in the vertex cover. 


We need to express the problem in terms of integer programming. Thus
\begin{equation}
\sum_{\forall v \in V} w(v) x(v)  
\end{equation}
where $x(v)=1$ if vertex is in cover in cover otherwise 0. Subject to
\begin{equation}
  x(u)+x(v) \geq 1 \forall (u,v) \in E
\end{equation}
(At least one of two adjacent vertices has to be in vertex cover.) and
\begin{equation}
    x(v)  \in \{0,1\} \forall v \in V 
\end{equation}

We need to transform the integer programming problem into a linear program by relaxing the last constraint, i.e. $0 \leq x(v) \leq 1 \qquad \forall v \in V$. This linear program can be solved optimal in polynomial time. 

The solution of the linear program related to the solution to the integer problem-> Linear program gives us at leas the value of the integer programming problem. Linear program therefore gives us a lower bound.

Approx Exam
Vertex cover appeox 2

Tsp approx 2 with triangle eq. Interesting if triangle not holds
Non approx algo if triangle not holds

Set cover

Good example Also to show how linear programm Can solcve set cover

3CNF?!               

The whole chapter 35 has been treated in the lecture, except for the details of the proof of the approximation factor achieved by the greedy SET-COVER (pages 1120 and 1121), and except for the detailed computations in the proof of Theorem 35.8 (for  SUBSET SUM, pages 1132 and 1133).

For the approximation ratio for the greedy SET-COVER algorithms, another simpler proof was given during the lecture. It is based only on the number of remaining uncovered elements which are covered by the next set  selected by the greedy algorithm. Namely, if r is the number of remaining uncovered elements, the next set selected by the greedy algrorithm covers at least r/OPT elements, where OPT denotes the number of sets in the optimal solution (i.e. the minimum). This argument alone suffices to conclude that when the greedy algorithm selects at most OPT sets,  at least half of the remaining uncovered elements are covered. Repeating this argument recursively, yields that all elements are covered after selecting greedily at most OPT times $\O(log n)$ sets. For the purposes of the exam, it would suffice if you understand this argument (especially if you think that the full proof in the book is too difficult).

Similarly, in the exam you will not be required to give an account for the detailed computations in the proof of Theorem 35.8 (SUBSET-SUM), but you should try to understand the idea behind how trimming of the lists is done, and why it works. That is,

(a) on one hand it keeps only a polynomial number of elements in the list, but

(b) at the same time the allowed error is so small, that although it may increase at each step, it still does not add to something which is so big that it violates the required approximation bound.

Reason about vertex cover is factor 2.

% section approximation_algorithms (end)

\section{Randomized Algoritms} % (fold)
\label{sec:randomized_algoritms}
Randomized Algoritms - CLRS, Sections  5.1, 5.2, 5.3; 7.3, 9.2, 12.4, 35.4 (first part); (without the details of the probabilistic proofs in 7.3, 9.2 and 12.4)                                                                                                                                                    

Some problems can be solved in a simple way by using randomization. E.g. median finding. 

In median finding there is a linear algorithm that finds it deterministic, but a randomized algorithm is actual more efficient.

Affordability: Walking in a maze, in an "oblivious" manner i.e. we don't remember where we have been/walked until a certain point. At any node flip a coin to determine the direction. By doing this enough times you're guaranteed to sooner or later to arrive at the destination/goal. Such walks are called "random walks". 


Hiring problem: A way to model certain procedures, so can determine the worst case, expected cost and how we can use randomization to avoid worst case.


We want to hire a person. We have $n$ candidates. We interview each candidate, and if candidate $i$ is better than the previous best, we hire him.

The worst case is we hire all candidates, cost is thus $n$.

Expected hiring cost preciesly after the i'th interview is $1/i$

Expected total cost is $1+1/2+1/3+...+1/n \approx ln(n)$.

In order to arrive at this result we used the \emph{linearity of expectations}. Linearity of expectations means that the expected value of a sum equals the expected value of each i'th terms of the sum. Dice example.Throwing a dice yields a number in the interval $1-6$. The expected number is $3,5$. Throw the dice 10 times then the expected sum will be 35. This holds only for summation not products. For products it only holds for unrelated events (iid).

The worst case can be avoided by shuffling the list of candidates in a random permutation.


----------------

For the exam you should read and try to understand Sections 5.1, 5.2 and 5.3, the material for the randomized algorithm for MAX-3-CNF in Section 35.4, and give an idea of applications of randomization to sorting (Quicksort, Section 7), Selection (Section 9.2), and binary search trees (Section 12.4).

You will not be required to give proofs for expected bounds for Quicksort, Selection and binary search trees, but you should try to give an intuitive explanation for how/why randomization works in these cases.
You will not be required to give the full proofs of Lemma 5.4 and 5.5 as they are given in the book (unless you want it), but you should try to convince yourself that these Lemmas are true and try to be able to argue about it. 


% section randomized_algoritms (end)

\section{Computational Geometry, Convex hulls} % (fold)
\label{sec:computational_geometry_convex_hulls}
Computational Geometry, Convex  hulls, CLRS,  Chapter 33.3 and the papers by [Kirkpatrick\&Seidel] and [Chan] (only 2D case in both articles).

Given a set of points $P$, the convex hull problem seeks to find a convex set containing all the points in $P$.

Let $S$ be a convex set. Then for any two points $a,b \in S$ the following is true
\begin{equation}
  (t-1)a+tb \qquad t \in [0,1]
\end{equation}
thus, there exists a line between any two points in $S$, such that the line between them is contained within $S$.

In the following we assume that no points has the same $x$- or $y$- coordinates and no three points are collinear. This is true in the continous world, but watch out when going into the discrete world of computers!

We denote the convex hull of a set $S$ to be $CH(S)$. There exists several algorithms to calculate the convex hull. Int he following, Grahams scan, Jarvis' march, quickhull, randomized incremental and marriage before conquest is explained in detail.

\subsection{Grahams scan} % (fold)
\label{sub:grahams_scan}
Grahams scan has a running time of $\O(n\log(n))$. It starts by choosing a the point $p_0 \in S$, with the lowest $y$-coordinate. This can be done in $\O(n)$. It then sorts the remaining points $p_i \in S$ by the angle between the line $(p_0, p_i)$ and the $x$-axis. This sorting can be done in $n \log(n)$ by e.g. heap sort\footnote{Heap sort uses a heap, i.e. a tree datastructure where the largest element is on top.} 

Put $p_0, p_1, p_2$ in the list of nodes that constitutes the convex hull. If making a left turn when adding $p_3$, remove $p_2$ and add $p_3 to the list$. Otherwise if making a right turn, add $p_3$ to the list. Continue adding nodes. If adding node $p_j$ creates a left turn, then remove node $p_{j-1}$ and add $p_j$. Otherwise just add $p_j$. When last node has been reached, the convex hull is done.

The correctness of Grahams scan can be explained by the following observations. 

\begin{itemize}
  \item Grahams scan will never go backwards behind the initial node. 
  \item When ariving at point $p_i$ all points between the initial node and the point $p_i$ are right turns on the polygonal line constructed so far
  \item After arriving at the initial node by a right turn, we get a polygonal line consisting of purely right turns. 
\end{itemize}



The time complexity is $\O(n\log(n))$ since sorting takes $\O(n\log(n))$ and the scanning takes $\O(n)$, since each point is only considered once. The total time complexity is thus $\O(n\log(n)+n)=\O(n\log(n))$.

% subsection grahams_scan (end)

\subsection{Jarvis' march} % (fold)
\label{sub:jarvis_march}
Jarvis' march is also knows as the `Giftwrapping algorithm'. It has a complexity of $\O(nh)$, where $n$ is the number of nodes, and $h$ is the number of nodes in the convex hull. Since part of the complexity relies on the final output, the algorithm is \emph{output sensitive}.

Find the point, $p_0$, which is placed leftmost. This point can be found in $\O(n)$. Add $p_o$ to the convex hull list. Now find the point $p_1$ which has every other point $p_i$ to the right and add it to the list of convex hull nodes. This can also be done in $\O(n)$ by comparing polar angles from $p_0$. Continue to add $p_i$ to the list such that every other node is to the right of $p_i$. Continue until the $p_i=p_0$.

The complexity of Jarvis' march can be computed as the time it takes to find $p_i$ times the number of nodes, $h$ in the convex hull. The complexity is thus $\O(nh)$.
% subsection jarvis_march (end)


\subsection{Quickhull} % (fold)
\label{sub:quickhull}
Quickhull is an algorithm that has an expected running time of $\O(n\log(n))$, and a worst case running time of $\O(n^2)$. The algorithm starts by finding the leftmost and rightmost points, $A$ and $B$. It then draws a line between these two points, and splits the point set $S$ into two. Let the set $S_1$ contain the points above the line, and $S_2$ contain the points below the line. 

For each of these two sets we proceed recursively.

Find the point, $P$ farthest away from the line. the convex hull must contain $P$, so insert the point between $A$ and $B$. A triangle is formed by $ABP$. Remove all points from $S$ that is contained within this triangle. The cross product can be used to calculate wether a point lies inside a triangle.                                                                                        

We form two new sets. One set containing the set of points above the line $AP$. The other set containing the line $BP$. The line $AB$ is then replaced by these two lines. and the algorithm proceeds recursively. The algorithm stops when the sets are empty or if it only consist of one node.

If the partitioning yields balanced sets, the the expected running time is $\O(n\log(n))$. If the partitioning is extremely unbalanced then the running time is $\O(n^2)$. A example of an extremely unbalanced set of points, is when the points lie on a half circle.


% subsection quickhull (end)

\subsection{Marriage before conquest (MBC)} % (fold)
\label{sub:marriage_before_conquest_mbc_}
The Kirkpatrick-Seidel algorithm (Marriage before conquest) is output sensitive and has running time $\O(n\log{h})$, where $h$ is the number of points in the convex hull.

The algorithm first calculates the upper hull and then the lower hull. It then merges these two into the final convex hull. We can safely assume that the merging of the two half hulls can be performed in $\O(1)$.

Let $S$ be the set of points. Divide $S$ into two sets, by dividing $S$ with the line $(p_j,p_k)$, where $p_j \in S$ is the point with minimum $x$-value and $p_k \in S$ is the point with maximum $x$-value. Let $P$ be one of the two sets.

The algorithm then calculates the median $x$-coordinate $M$ of the points in $P$. It the finds the bridge segment that crosses the vertical line $x=M$. It finds this bridge segment by a technique called Prune \& Search. $x=M$ divides $P$ in half. The bridge segment across this line, will be part of the final convex hull. Finding the bridge is done by the following procedure.

Randomly pair the points in $P$ into $n/2$ distinct line segments. Name the line segments $q_i$. Let the point of line segment $q_i$ with the lowest $x$-value be called $q_{il}$, and the point with the largest $x$-value $q_{ir}$. This pairing can be done in $\O(n)$.

Determine the median slope, $m$ of all the distinct line segments. If the number of points is odd, there will be a point that is not part of a line segment. Give this point a slope of $0$. If the number of line segments is even there are two choices for the median slope. Let $m$ be the max of these two slopes.

Construct a sweep line, $L$, having the median slope, i.e $y = mx+b$. Find a point $p_t$ such that $L$ is a supporting line\footnote{A supporting line for a set $S$ is a line that contains a point $p_i \in S$ an no other points above.} for $P$ at $p_t$, this can be done by translating. We call $p_t$ the top point. Let $p_j.x$ define the $x$-coordinate of the point $p_j$. If $p_t.x \geq M$, i.e the top point is to the right of the vertical line M, then for each line segment with slope $< m$ remove the right point of the line segment, i.e $q_{ir}$. If $p_t.x < M$, i.e. the top point is to the left of the vertical line $M$, then for each line segment with slope $>m$, remove the left point $q_{il}$. Repeat this until only two points are left. We know that at least half of the line segments has a slope greater than $m$, therefore we can conclude that we at each iteration of the bridge finding removes $1/4$ of the points. Note that the points are only removed in the current step where we find the bridge, not the set $P$.

Delete the points under the bridge, and split $P$ into the two half's divided by the vertical line. Continue recursively on each half.

The complexity of the bridge finding is as follows. Pairwise point matching takes $\O(n)$, finding the median slope takes $\O(n)$, slope translation takes $\O(n)$. Each time we remove points we are sure to remove $1/4$ of the points. This yields 
\begin{align*}
T(n) &= \O(1) &\qquad n=2\\ 
T(n) &= T(3n/4) + \O(n) &\qquad \text{if } n>2
\end{align*}
thus the complexity of the bridge finding and finding the median is $T(n)=\O(n)$.

The total overall complexity can be bounded by the following function
\begin{align*}
f(n,h) &= cn &\qquad h=2  \\ 
f(n,h) &= cn + \max_{h_l+h_r = h}\left\{f(n/2,h_l)+f(n/2,h_r)\right\} &\qquad h>2
\end{align*}
where $c$ is a positive constant. The max is introduced because the algorithm is output sensitive. The claim is that the complexity is $f(n,h) = \O(n\log(h))$, thus we can find a upper bound by the function $cn\log(h)$.

\begin{proof}

  For $h=2$                
  \begin{equation}
    f(n,h) = c_1n \leq cn\log(2)
  \end{equation}
  this trivially holds if $c_1 \leq c$
  
  Assume $h>2$ and bu subsitution we have
  \begin{align*}
   f(n,h) &= cn + \max_{h_l+h_r = h}\left\{cn/2\log(h_l)+cn/2\log(h_r)\right\} \\
          &= cn + cn/2\max_{h_l+h_r = h}\left\{\log(h_l)+\log(h_r)\right\} \\
          &= cn + cn/2\max_{h_l+h_r = h}\left\{\log(h_lh_r)\right\} \\          
          &= cn + cn/2\max_{h_l+h_r = h}\left\{\log(h_l(h-h_l))\right\} \\         
          &= cn + cn/2\max_{h_l+h_r = h}\left\{\log(hh_l-h_l^2))\right\}                    
  \end{align*}
    
  When does the function $g(h_l) = \log(hh_l-h_l^2)$ takes it's maximum. It does when the derivative is $0$.
  \begin{equation}
    g_{h_l}'(h_l,h) = \frac{1}{hh_l-h_l^2} (h-2h_l) = 0 
  \end{equation}
  If $g_{h_l}'(h_l)=0$ then $h-2h_l=0$ yielding $h_l = \frac{h}{2}$. Thus
  \begin{align*}
   f(n,h) &= cn + cn/2\log(h\frac{h}{2}-\frac{h^2}{2^2})) \\
          &= cn + cn/2\log(\frac{h^2}{2}-\frac{h^2}{2^2})) \\   
          &= cn + cn/2\log(\frac{2h^2}{4}-\frac{h^2}{2^2})) \\
          &= cn + cn/2\log(\frac{h^2}{2^2})) \\                       
          &= cn + 2cn/2\log(\frac{h}{2}) \\                                 
          &= cn + cn\log(\frac{h}{2})                                 
  \end{align*}
   which has a running time of $\O(n\log(h))$
   
\end{proof}

% subsection marriage_before_conquest_mbc_ (end)


\subsection{Chan and relations to MBC} % (fold)
\label{sub:chan_and_relations_to_mbc}
\todo{Make chan!}  
The reading material for the Convex Hulls lecture consisted of the papers by Chan (2d case) and by Kirkpatrick\&Seidel, in addition to Section 33-3 in Cormen (see also the slides). In the exam you should be able to define the Convex Hull problem, you should know the underlying idea of the algorithms, and you should be able to argue for their correctness and running time.

A series of different algorithms have been covered: Edge pruning, Graham's scan, Jarvis' march, Quickhull, Randomized Incremental, Divide and conquer, Marriage-before-conquest (Kirkpatrick-Seidel) and Chan's algorithm -- Chan's was covered in the exercises, and the others were covered in the lecture. The concept of convex hull as well as the worst-case and expected complexity of QuickHull were also covered in the exercises, and are relevant for the exam.

The Marriage-before-conquest and Chan algorithms are the optimal algorithms, and hence also the most important -- you should be able to explain the basic underlying mechanisms and the structure of both algorithms. For Chan's algorithm you should be able to prove complexity and discuss the relation of Chan's algorithm with Jarvis march. For a good grade, you should also be able to argue for the complexity of the Marriage-before-conquest algorithm.

% subsection chan_and_relations_to_mbc (end)

% section computational_geometry_convex_hulls (end)


\section{Computational Geometry, Delaunay triangulatiom} % (fold)
\label{sec:computational_geometry_delaunay_triangulatiom}


\subsection{Applications} % (fold)
\label{sub:applications}
Triangulation is used in graphics and movies. It can also be used to model terrain when the terrain is represented as a bunch of sample points where each sample point is representing the height of the terrain compared to, lets say, sea level. A terrain visualized solely by height samples is not that interesting an doesn't look very natural! Instead we can do triangulation of the samples in 2D, and after the triangulation lift the points op in 3D yielding a triangulated surface, representing a terrain. 

The central question here is how we triangulate the points? and if there are multiple methods how do we choose the method that gives us the most appropriate triangle net? In the following subsections we will answer these two questions.
% subsection applications (end)applications


\subsection{Definition} % (fold)
\label{sub:definition}

What do we mean by a good triangulation?
Simple case is to connect one point to every other point. This is NOT a good triangulation. The ideal triangulation is a triabgulation that is ballanced, i.e. the we want to avoid small angles. 

We define angle optimality as follows.

Let $T$ be a triangulation of $P$. Let $T$ consist of $m$ triangles. Then $T$ has $3m$ angles. Let the angles be in a sorted vector in increasing order. Denote this vector $A(T)$ We call this vector an \emph{angle vector}. Let $T'$ be another triangulation of $P$. We say that $T$ is \emph{angel-optimal} if $T$ is lexicographically larger than $\forall T'\in P$.

Lexicographically larger means that for some index $i$ the angles after $i$ in $A(T)$ is larger than the angels in $A(T')$. E.g.

\begin{equation} 
\left(
\begin{array}{r} 
   1  \\
   3 \\
   5 \\
   7 
\end{array} 
\right) >   
\left(
\begin{array}{r} 
   1  \\
   2 \\
   5 \\
   7 
\end{array} 
\right)
\end{equation} 
the reason for this definition, is we want as uniform angles as possible in all triangles.


We define maximal planar subdivision as
\begin{definition}
Maximal planar subdivision: A subdivision $S$ such that no edge connecting two vertices can be added to $S$ without destroying it's planarity, i.e. any edge not in $S$ intersects and edge $e \in S$.  
\end{definition}
from the maximal planar subdivision we can define the triangulation as
\begin{definition}
Triangulation of set of points $P$: A maximal planar subdivision whose vertices are elements of $P$.  
\end{definition}

% subsection definition (end)



\subsection{Edge flip} % (fold)
\label{sub:edge_flip}
Given two adjacent triangles $p_1 p_2 p_4$ and $p_2 p_3 p_4$, one can do an edge flip as follows. Remove the common edge by creating two new triangles consisting of $p_1 p_3 p_4$ and $p_1 p_2 p_3$. An illustration of an edge flip can be seen on figure \ref{fig6}.

In the two adjacent triangles there are 6 angles. If we can increase the minimum angle by doing a edge flip on the shared edge, we called the shared edge illegal.

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig6.pdf}
\caption{Example of an edge flip}
\label{fig6}
\end{figure}

Instead of checking wether an edge is illegal by computing all the angles, we can use the following observation

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig7.pdf}
\caption{If $p_1$ is inside the circumcircle then the edge between the two triangles is illegal an we perform an edge flip.}
\label{fig7}
\end{figure}
% subsection edge_flip (end)


\subsection{Delaunay triangulation} % (fold)
\label{sub:delaunay_triangulation}
The Delaunay triangulation for a set of points $P$ is a triangulation where no point $p_i \in P$ is inside the circumcircle of any triangle in the triangulation set. The Delaunay triangulation is actually the dual of the Voronoi diagram. figure \ref{fig8} shows this relation. 

The Voronoi diagram is shown as red on figure \ref{fig8}, while the triangulation is shown as black. A line in the Voronoi diagram separating two vertices, indicates that there is an edge between the two vertices in the triangulation.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig8.png}
\caption{Duality between the Delaunay triangulation and the Voronoi diagram.}
\label{fig8}
\end{figure}

Returning to the legal and illegal edges. Let $P$ be a set of points in the plane then a triangulation of $P$ is legal, \emph{if and only if}, the triangulation is a Delaunay triangulation.
% subsection delaunay_triangulation (end)


\subsection{Naive method} % (fold)
\label{sub:naive_method}
Given a set of points, \emph{take the convex hull}, add diagonals (edges that connects vertices), without crossing those we already have drawn, until there are no more vertices. The result is a triangulation. I.e. we partition the points into triangles.

In order to make the triangulation into a Delaunay triangulation, we can do edge flips until there are no more illegal edges.


The most straightforward way of efficiently computing the Delaunay triangulation is to repeatedly add one vertex at a time, retriangulating the affected parts of the graph. When a vertex v is added, we split in three the triangle that contains v, then we apply the flip algorithm. Done naively, this will take O(n) time: we search through all the triangles to find the one that contains v, then we potentially flip away every triangle. Then the overall runtime is O(n2).

% subsection naive_method (end)


\subsection{Computing the Delaunay triangulation} % (fold)
\label{sub:computing_the_delaunay_triangulation}
The algorithm is randomized incremental algorithm, adding one point at a time.

Let $P$ be the set of points we want to triangulate. Find the point with the highest $y$ coordinate, and name this point $p_0$. Make a big triangle, that contains all the points in $P$ such that $p_0$ is one of the corners in the triangle. 

Now pick a random point from $P$ and add it to the big triangle, such that the big triangle is divided into $3$ sub triangles. Run a legalize edge procedure, ensuring that all the edges are legalized.

Keep adding points from the set $P$, and legalize the edges of until $P$ is empty. 

As a final stage remove the points $p_{-1}$ and $p_{-2}$ along with the incident edges. 

THe data structure used is a point location structure. It is a tree like structure where the nodes defines the position of previous triangles and the leafs corresponding to the current visible triangles. 

Given a point the data structure makes it possible to locate the triangle of which the point is placed upon. 

Figure \ref{fig9} shows how the data structure is maintained when splitting existing triangles and flipping edges.
\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{figures/fig9.pdf}
\caption{Example of maintaining a data structure when flipping edges and dividing triangles.}
\label{fig9}
\end{figure}

The \emph{expected} running time of the algorithm is $\O(n\log(n))$. This can be explained as, it takes constant time to create new triangles the maximal number of triangles created is $\O(n)$. When identifying the triangle in which a point is located, we use the point location data structure, and can make this identification in $\O(\log(n))$.


% subsection computing_the_delaunay_triangulation (end)

                                       
% section computational_geometry_delaunay_triangulatiom (end)































\end{document}